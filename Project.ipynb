{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Converting Binary File to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bin_to_csv(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bin_to_csv(\"./data/train-images-idx3-ubyte\", \"./data/train-labels-idx1-ubyte\",\n",
    "        \"./data/fashion_mnist_train.csv\", 60000)\n",
    "convert_bin_to_csv(\"./data/t10k-images-idx3-ubyte\", \"./data/t10k-labels-idx1-ubyte\",\n",
    "        \"./data/fashion_mnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fashion MNIST Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        data = pd.read_csv(csv_file);\n",
    "        self.images = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28)\n",
    "        self.labels = np.array(data.iloc[:, 0]);\n",
    "        self.transform = transform;\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (torch.Tensor(image),torch.from_numpy(np.array(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(csv_file='data/fashion_mnist_train.csv')\n",
    "test_dataset = FashionMNIST(csv_file='data/fashion_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "n_iters = 6000\n",
    "num_epochs = int(n_iters / (len(train_dataset)/batch_size))\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel,self).__init__()\n",
    "        \n",
    "        #Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels = 16, kernel_size=5, stride = 1, padding =2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Maxpool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        #Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels = 32, kernel_size=5, stride = 1, padding =2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Maxpool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fcl1 = nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        #Maxpool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        #Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        #Maxpool 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fcl1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.015\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aishwarya/env/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, loss 0.26551762223243713, accuracy 84\n",
      "Iteration 1000, loss 0.34515175223350525, accuracy 85\n",
      "Iteration 1500, loss 0.5504879951477051, accuracy 84\n",
      "Iteration 2000, loss 0.39085257053375244, accuracy 85\n",
      "Iteration 2500, loss 0.32056155800819397, accuracy 86\n",
      "Iteration 3000, loss 0.3982406258583069, accuracy 85\n",
      "Iteration 3500, loss 0.3833635449409485, accuracy 85\n",
      "Iteration 4000, loss 0.34555724263191223, accuracy 85\n",
      "Iteration 4500, loss 0.2547236382961273, accuracy 84\n",
      "Iteration 5000, loss 0.10910201072692871, accuracy 86\n",
      "Iteration 5500, loss 0.4550250768661499, accuracy 86\n",
      "Iteration 6000, loss 0.29969465732574463, accuracy 86\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #load images as Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #calculate loss: softmax ---> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #getting gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter%500 == 0:\n",
    "            #Calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            #iterate through the test dataset\n",
    "            for images,labels in test_loader:\n",
    "                images = Variable(images)                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iteration {}, loss {}, accuracy {}'.format(iter, loss.data[0], accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
