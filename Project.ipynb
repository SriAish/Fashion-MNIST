{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST CNN Model Average accuracy of 86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Converting Binary File to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bin_to_csv(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    # Removing headers\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    \n",
    "    # array to store labels with image matrix\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        # writing into the CSV files\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting binary file to CSV files\n",
    "convert_bin_to_csv(\"./data/train-images-idx3-ubyte\", \"./data/train-labels-idx1-ubyte\",\n",
    "        \"./data/fashion_mnist_train.csv\", 60000)\n",
    "convert_bin_to_csv(\"./data/t10k-images-idx3-ubyte\", \"./data/t10k-labels-idx1-ubyte\",\n",
    "        \"./data/fashion_mnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fashion MNIST Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        data = pd.read_csv(csv_file);\n",
    "        # Turning the image matrix to the one commonly foun in PyTorch\n",
    "        self.images = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28)\n",
    "        self.labels = np.array(data.iloc[:, 0]);\n",
    "        self.transform = transform;\n",
    "\n",
    "    def __len__(self):\n",
    "        # Setting the standard length function\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Setting get function to use dataset as tuple\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (torch.Tensor(image),torch.from_numpy(np.array(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(csv_file='data/fashion_mnist_train.csv')\n",
    "test_dataset = FashionMNIST(csv_file='data/fashion_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "              0.,    0.,   41.,  188.,  103.,   54.,   48.,   43.,\n",
       "             87.,  168.,  133.,   16.,    0.,    0.,    0.,    0.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    1.,    0.,    0.,    0.,   49.,\n",
       "            136.,  219.,  216.,  228.,  236.,  255.,  255.,  255.,\n",
       "            255.,  217.,  215.,  254.,  231.,  160.,   45.,    0.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,   14.,  176.,  222.,\n",
       "            224.,  212.,  203.,  198.,  196.,  200.,  215.,  204.,\n",
       "            202.,  201.,  201.,  201.,  209.,  218.,  224.,  164.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,  188.,  219.,  200.,\n",
       "            198.,  202.,  198.,  199.,  199.,  201.,  196.,  198.,\n",
       "            198.,  200.,  200.,  200.,  200.,  201.,  200.,  225.,\n",
       "             41.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,   51.,  219.,  199.,  203.,\n",
       "            203.,  212.,  238.,  248.,  250.,  245.,  249.,  246.,\n",
       "            247.,  252.,  248.,  235.,  207.,  203.,  203.,  222.,\n",
       "            140.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,  116.,  226.,  206.,  204.,\n",
       "            207.,  204.,  101.,   75.,   47.,   73.,   48.,   50.,\n",
       "             45.,   51.,   63.,  113.,  222.,  202.,  206.,  220.,\n",
       "            224.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,  200.,  222.,  209.,  203.,\n",
       "            215.,  200.,    0.,   70.,   98.,    0.,  103.,   59.,\n",
       "             68.,   71.,   49.,    0.,  219.,  206.,  214.,  210.,\n",
       "            250.,   38.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,  247.,  218.,  212.,  210.,\n",
       "            215.,  214.,    0.,  254.,  243.,  139.,  255.,  174.,\n",
       "            251.,  255.,  205.,    0.,  215.,  217.,  214.,  208.,\n",
       "            220.,   95.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,   45.,  226.,  214.,  214.,  215.,\n",
       "            224.,  205.,    0.,   42.,   35.,   60.,   16.,   17.,\n",
       "             12.,   13.,   70.,    0.,  189.,  216.,  212.,  206.,\n",
       "            212.,  156.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,  164.,  235.,  214.,  211.,  220.,\n",
       "            216.,  201.,   52.,   71.,   89.,   94.,   83.,   78.,\n",
       "             70.,   76.,   92.,   87.,  206.,  207.,  222.,  213.,\n",
       "            219.,  208.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,  106.,  187.,  223.,  237.,  248.,\n",
       "            211.,  198.,  252.,  250.,  248.,  245.,  248.,  252.,\n",
       "            253.,  250.,  252.,  239.,  201.,  212.,  225.,  215.,\n",
       "            193.,  113.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,   17.,   54.,  159.,\n",
       "            222.,  193.,  208.,  192.,  197.,  200.,  200.,  200.,\n",
       "            200.,  201.,  203.,  195.,  210.,  165.,    0.,    0.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   47.,\n",
       "            225.,  192.,  214.,  203.,  206.,  204.,  204.,  205.,\n",
       "            206.,  204.,  212.,  197.,  218.,  107.,    0.,    0.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    1.,    6.,    0.,   46.,\n",
       "            212.,  195.,  212.,  202.,  206.,  205.,  204.,  205.,\n",
       "            206.,  204.,  212.,  200.,  218.,   91.,    0.,    3.,\n",
       "              1.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,   11.,\n",
       "            197.,  199.,  205.,  202.,  205.,  206.,  204.,  205.,\n",
       "            207.,  204.,  205.,  205.,  218.,   77.,    0.,    5.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    3.,    0.,    2.,\n",
       "            191.,  198.,  201.,  205.,  206.,  205.,  205.,  206.,\n",
       "            209.,  206.,  199.,  209.,  219.,   74.,    0.,    5.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    2.,    0.,    0.,\n",
       "            188.,  197.,  200.,  207.,  207.,  204.,  207.,  207.,\n",
       "            210.,  208.,  198.,  207.,  221.,   72.,    0.,    4.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    2.,    0.,    0.,\n",
       "            215.,  198.,  203.,  206.,  208.,  205.,  207.,  207.,\n",
       "            210.,  208.,  200.,  202.,  222.,   75.,    0.,    4.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            212.,  198.,  209.,  206.,  209.,  206.,  208.,  207.,\n",
       "            211.,  206.,  205.,  198.,  221.,   80.,    0.,    3.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            204.,  201.,  205.,  208.,  207.,  205.,  211.,  205.,\n",
       "            210.,  210.,  209.,  195.,  221.,   96.,    0.,    3.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            202.,  201.,  205.,  209.,  207.,  205.,  213.,  206.,\n",
       "            210.,  209.,  210.,  194.,  217.,  105.,    0.,    2.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            204.,  204.,  205.,  208.,  207.,  205.,  215.,  207.,\n",
       "            210.,  208.,  211.,  193.,  213.,  115.,    0.,    2.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            204.,  207.,  207.,  208.,  206.,  206.,  215.,  210.,\n",
       "            210.,  207.,  212.,  195.,  210.,  118.,    0.,    2.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            198.,  208.,  208.,  208.,  204.,  207.,  212.,  212.,\n",
       "            210.,  207.,  211.,  196.,  207.,  121.,    0.,    1.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            198.,  210.,  207.,  208.,  206.,  209.,  213.,  212.,\n",
       "            211.,  207.,  210.,  197.,  207.,  124.,    0.,    1.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            172.,  210.,  203.,  201.,  199.,  204.,  207.,  205.,\n",
       "            204.,  201.,  205.,  197.,  206.,  127.,    0.,    0.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            188.,  221.,  214.,  234.,  236.,  238.,  244.,  244.,\n",
       "            244.,  240.,  243.,  214.,  224.,  162.,    0.,    2.,\n",
       "              0.,    0.,    0.,    0.],\n",
       "          [   0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "            139.,  146.,  130.,  135.,  135.,  137.,  125.,  124.,\n",
       "            125.,  121.,  119.,  114.,  130.,   76.,    0.,    0.,\n",
       "              0.,    0.,    0.,    0.]]]), tensor(0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe422856240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEWtJREFUeJzt3XuMXdV1x/Hfwp6xPUOwx6aYwTE4BQOyLHBgZIECJaUNEBQECImHEHIliBFKoJGCBKJ/lH+QUCFJkaginGJiVylJUWLgDwQBVAkiSoyxXewAtXHk4Bdj4wd+4werf8wBDTB37WHOPffc8f5+JMszd90zd8+Bn8+dWWfvbe4uAPk5ru4BAKgH4QcyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8jU2Fa+mJlxO+EIjB8/PqyfeuqpDWs7duwIj92/f39YT90BmqpPmDChYa2npyc89uDBg2G9v78/rB89ejSsH6vc3YbzvFLhN7MrJD0iaYykf3f3B8t8vTqZxeerztugZ8yYEdYfffTRhrWnnnoqPHbFihVh/dChQ2H98OHDYX327NkNa9dee2147Lp168L6Qw89FNZ37doV1nM34rf9ZjZG0r9J+q6kWZJuMrNZzRoYgGqV+Zl/rqT33P3P7n5I0q8lXd2cYQGoWpnwT5O0YdDnG4vHPsfM5pvZMjNbVuK1ADRZ5b/wc/cFkhZI/MIPaCdlrvybJE0f9PnXi8cAjAJlwv+GpJlm9g0z65R0o6RnmzMsAFWzMi0sM7tS0r9qoNW30N0fSDy/srf9dbbq5syZE9ZvvPHGsH7dddeF9VS/uru7u2Et6rNL0pQpU8J6ldasWRPWP/nkk7B+1llnhfXoPoAXXnghPPbhhx8O66tXrw7rdWpJn9/dn5P0XJmvAaAe3N4LZIrwA5ki/ECmCD+QKcIPZIrwA5kq1ef/yi/Wxrf3nnDCCWF98eLFDWvnnHNOeOxxx8X/xu7Zsyesp+a1R9NqU/cIdHR0hPWJEyeG9X379oX1qFdf9f970ToIqfsfOjs7w/qrr74a1m+55ZawXqXh9vm58gOZIvxApgg/kCnCD2SK8AOZIvxApmj1FV566aWwftpppzWsbd++PTw2NTV17Nh4cuWRI0fCemo6cyTVhkyt3jtmzJjKXrtKZaeA9/b2hvXLL788rL/77rthvQxafQBChB/IFOEHMkX4gUwRfiBThB/IFOEHMtXSLbrrdP7554f1qI8vSR9++GHDWqpPn+qFp7bgnjbtS7ugfU5XV1fDWqqXntplN/W9paYMR/301HTi1P0NqanQGzduHPHXTkl937fddltYv/vuu0u9fjNw5QcyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFNlt+heL2mPpKOSjrh7X+L5tc3nT/VV77rrrrAe9flT8/VTff5Uz/ixxx4L65s3b25Yi3rdknTKKaeE9S1btoT1MusBjBs3Ljz2+OOPD+vnnXdeWL/zzjsb1qL/nlL6/obUUu+p42fMmBHWy2jJFt2Fv3X3+EwCaDu87QcyVTb8Lun3Zvammc1vxoAAtEbZt/0XufsmMztJ0otm9q67vzL4CcU/CvzDALSZUld+d99U/L1V0hJJc4d4zgJ370v9MhBAa404/GbWbWZf+/RjSZdJWt2sgQGoVpm3/VMlLSmmbI6V9J/u/nxTRgWgctms2//666+H9ZNOOimsR3PHU2vbp/rVH330UVi/4IILwvpll13WsJZaC+CJJ54I67fffntYX706frMXbYWduv+hv78/rK9cuTKsr127tmEttRZAao2F1HoAZ599dlifPXt2w9qaNWvCY1NYtx9AiPADmSL8QKYIP5Apwg9kivADmcpm6e5zzz03rG/YsCGsR1NXU1NTU1LTQ1Oef77x7RX79u0Lj501a1ZYT02FXrJkSVi/6qqrGtZS016XL18e1lPLsUftuO7u7vDY1DTr1DTu999/P6xfeOGFDWtlW33DxZUfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFMHTN9/miKpCRt27YtrKemaEbTT6NtqKV4Wqskbd++PaynRN/7xx9/HB7b29sb1h944IGwnvreoy3AU8dGvfDhiJY0T011LtvnP3DgQFi/+OKLG9YWLVoUHtssXPmBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8jUMdPnv+eee8J6qte+d+/esB71fVNf++DBg2E9dY9BX1+82dGUKVMa1iZPnhwe29HREdanTp0a1qM+vhR/752dneGxkyZNCus33HBDWO/p6WlYS/XhJ06cGNZTx6e+t9R/01bgyg9kivADmSL8QKYIP5Apwg9kivADmSL8QKaSfX4zWyjpe5K2uvvs4rHJkn4jaYak9ZKud/ed1Q0z7bXXXgvrJ598clg/44wzwnq0tn5qDfhoq2gpPXc8tb14NLc8Ne889dqpbbRTa+9Hc/ZTrx3tlSClt9mO1r/v6uoKj01936mxRWsJSNLTTz8d1lthOFf+X0q64guP3SvpZXefKenl4nMAo0gy/O7+iqQdX3j4akmfLjeySNI1TR4XgIqN9Gf+qe6+pfj4A0nxPaAA2k7pe/vd3c3MG9XNbL6k+WVfB0BzjfTK329mvZJU/L210RPdfYG797l7/TMZAHxmpOF/VtK84uN5kp5pznAAtEoy/Gb2pKT/kXSWmW00s1slPSjpO2a2VtLfF58DGEXMveGP681/seB3A3WL5n5L0syZMxvW7rjjjvDYSy65JKxv2LAhrKfmlu/atathLTVfP9XPrlJq3f5ULz21TkJ03latWhUee/PNN4f1dubu8YktcIcfkCnCD2SK8AOZIvxApgg/kCnCD2TqmFm6u6ydO+MZyUuXLm1YS22Dfemll4b1VLs1tQx0NKU41cpLTflNSbXronrqtceNGxfWDx06FNbHjx/fsJaaAp4DrvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2Qqmz5/qh+dmvoa9ZRTffrdu3eH9VQvPrXEdZlp2anz0sop319VmenI0TToZrx26h6GdjivXPmBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8hUNn3+VF/18OHDI/7a69atC+upPn9qm+vUvPVI6vuuus+f+vqR1PedujcjkvpvkpJaVjx1b0Y74MoPZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmkn1+M1so6XuStrr77OKx+yV9X9K24mn3uftzVQ2yFcr0bQ8cOBAem+pXp9anP3LkSFiP7hMo28cvsy6/FJ/X1Gun9kPo6uoK69HYUuc0B8O58v9S0hVDPP4zd59T/BnVwQdylAy/u78iaUcLxgKghcr8zP9DM3vLzBaaWU/TRgSgJUYa/p9LOl3SHElbJP2k0RPNbL6ZLTOzZSN8LQAVGFH43b3f3Y+6+yeSfiFpbvDcBe7e5+59Ix0kgOYbUfjNrHfQp9dKWt2c4QBoleG0+p6U9G1JJ5rZRkn/LOnbZjZHkktaL+n2CscIoALJ8Lv7TUM8/HgFY6lVmXnrqTXay667n6qn7lGIpMZeZm18Ke61p8ad+r5TYy9zj0FKO6y7XxZ3+AGZIvxApgg/kCnCD2SK8AOZIvxAprJZurtO06ZNC+s7d+4M66l2W9R2SrXTyiytXbXU2FPLrUffW9kW5rGAKz+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5miz1+ocopm2WWiOzs7w3o0Zbjs0ttVLv2dmpKb2oI7tbR3NLYy23unvvZowZUfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFM0edvgVQ/OjW3PHWfQHR8qpee6lenxpbafjz6+tHW4qljJWn//v1hPTJp0qQRH3us4MoPZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmkn1+M5suabGkqZJc0gJ3f8TMJkv6jaQZktZLut7d4wXoM5XqtZcVzZkvO++8ynX/y6wFMJzjo/sjJkyYEB6bkst8/iOSfuzusyRdIOkHZjZL0r2SXnb3mZJeLj4HMEokw+/uW9x9efHxHknvSJom6WpJi4qnLZJ0TVWDBNB8X+lnfjObIembkv4oaaq7bylKH2jgxwIAo8Sw7+03s+Ml/VbSj9x99+Cfx9zdzWzIH4LMbL6k+WUHCqC5hnXlN7MODQT/V+7+u+LhfjPrLeq9krYOday7L3D3Pnfva8aAATRHMvw2cIl/XNI77v7TQaVnJc0rPp4n6ZnmDw9AVYbztv9bkm6RtMrMVhaP3SfpQUn/ZWa3SvqLpOurGeLol2qXlVVl26nOVl/qtcu0+rq6usJjc5AMv7v/QVKj/8J/19zhAGgV7vADMkX4gUwRfiBThB/IFOEHMkX4gUyxdHehzimaqeWxyyg7bTalzNirnm4cbV1e5TkfLbjyA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QKfr8hbLLREdS21hXObc8tWx42e3BqzxvZVXZ589l6W4AxyDCD2SK8AOZIvxApgg/kCnCD2SK8AOZos/fBsrMS5fiXnvqa5etp+4jqHNd/wjz+bnyA9ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QqWSf38ymS1osaaokl7TA3R8xs/slfV/StuKp97n7c1UNtGpVzs/evHlzWD/zzDPDempOfdRrT/XhOzo6Rvy1h1OPzmvq/oWxY8vdhhK9NvP5h3eTzxFJP3b35Wb2NUlvmtmLRe1n7v5wdcMDUJVk+N19i6Qtxcd7zOwdSdOqHhiAan2ln/nNbIakb0r6Y/HQD83sLTNbaGY9DY6Zb2bLzGxZqZECaKphh9/Mjpf0W0k/cvfdkn4u6XRJczTwzuAnQx3n7gvcvc/d+5owXgBNMqzwm1mHBoL/K3f/nSS5e7+7H3X3TyT9QtLc6oYJoNmS4beBaVmPS3rH3X866PHeQU+7VtLq5g8PQFWG89v+b0m6RdIqM1tZPHafpJvMbI4G2n/rJd1eyQiPAZMmTQrr3d3dYT3V8jrxxBMb1spO2U21AstItfpS7bgNGzaE9WhJ9NNPPz08NqXsVOd2MJzf9v9B0lCTskdtTx8Ad/gB2SL8QKYIP5Apwg9kivADmSL8QKZYurtQ5VbTK1asCOtvv/12WN+1a1dYL9OLT/Wr9+7dG9ZT5yU6r2WmKkvprc97eoacbiJJWrp0aXhsymjo46dw5QcyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFPWyiWIzWybpL8MeuhESR+2bABfTbuOrV3HJTG2kWrm2E5z978azhNbGv4vvbjZsnZd269dx9au45IY20jVNTbe9gOZIvxApuoO/4KaXz/SrmNr13FJjG2kahlbrT/zA6hP3Vd+ADWpJfxmdoWZ/Z+ZvWdm99YxhkbMbL2ZrTKzlXVvMVZsg7bVzFYPemyymb1oZmuLvxvPW2392O43s03FuVtpZlfWNLbpZvbfZva2mf3JzP6xeLzWcxeMq5bz1vK3/WY2RtIaSd+RtFHSG5Jucvd4UnuLmNl6SX3uXntP2Mz+RtJeSYvdfXbx2L9I2uHuDxb/cPa4+z1tMrb7Je2te+fmYkOZ3sE7S0u6RtI/qMZzF4zretVw3uq48s+V9J67/9ndD0n6taSraxhH23P3VyTt+MLDV0taVHy8SAP/87Rcg7G1BXff4u7Li4/3SPp0Z+laz10wrlrUEf5pkgZvtbJR7bXlt0v6vZm9aWbz6x7MEKYW26ZL0geSptY5mCEkd25upS/sLN02524kO143G7/w+7KL3P08Sd+V9IPi7W1b8oGf2dqpXTOsnZtbZYidpT9T57kb6Y7XzVZH+DdJmj7o868Xj7UFd99U/L1V0hK13+7D/Z9uklr8vbXm8XymnXZuHmpnabXBuWunHa/rCP8bkmaa2TfMrFPSjZKerWEcX2Jm3cUvYmRm3ZIuU/vtPvyspHnFx/MkPVPjWD6nXXZubrSztGo+d22347W7t/yPpCs18Bv/dZL+qY4xNBjXX0v63+LPn+oem6QnNfA28LAGfjdyq6Qpkl6WtFbSS5Imt9HY/kPSKklvaSBovTWN7SINvKV/S9LK4s+VdZ+7YFy1nDfu8AMyxS/8gEwRfiBThB/IFOEHMkX4gUwRfiBThB/IFOEHMvX/wJIe16plA4kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "# 6000 iterations\n",
    "# More iterations don't lead to any significant change\n",
    "# Lesser iterations cause a drop of 3-4%\n",
    "n_iters = 6000\n",
    "num_epochs = int(n_iters / (len(train_dataset)/batch_size))\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief on model class\n",
    "\n",
    "1. No input needs to be passed while initializing all the sizes have been precomputed and used. \n",
    "2. Same padding is used for better results\n",
    "3. 2 Convolution layers have been used (3rd layer doesn't provide much benefit)\n",
    "4. ReLu has been used as it provides best result in CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel,self).__init__()\n",
    "        \n",
    "        #Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels = 16, kernel_size=5, stride = 1, padding =2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Maxpool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        #Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels = 32, kernel_size=5, stride = 1, padding =2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Maxpool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Final out\n",
    "        self.fcl1 = nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        #Maxpool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        #Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        #Maxpool 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        #Final Out\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fcl1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After my trial I got the best result with a learning rate of 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.015\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief about the training \n",
    "\n",
    "1. SGD is used as optimizer as it's Fast\n",
    "2. After every 500 iterations average accuracy is printed\n",
    "3. Cross Entropy Loss is used to calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aishwarya/env/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, loss 0.26551762223243713, accuracy 84\n",
      "Iteration 1000, loss 0.34515175223350525, accuracy 85\n",
      "Iteration 1500, loss 0.5504879951477051, accuracy 84\n",
      "Iteration 2000, loss 0.39085257053375244, accuracy 85\n",
      "Iteration 2500, loss 0.32056155800819397, accuracy 86\n",
      "Iteration 3000, loss 0.3982406258583069, accuracy 85\n",
      "Iteration 3500, loss 0.3833635449409485, accuracy 85\n",
      "Iteration 4000, loss 0.34555724263191223, accuracy 85\n",
      "Iteration 4500, loss 0.2547236382961273, accuracy 84\n",
      "Iteration 5000, loss 0.10910201072692871, accuracy 86\n",
      "Iteration 5500, loss 0.4550250768661499, accuracy 86\n",
      "Iteration 6000, loss 0.29969465732574463, accuracy 86\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #load images as Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #calculate loss: softmax ---> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #getting gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter%500 == 0:\n",
    "            #Calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            #iterate through the test dataset\n",
    "            for images,labels in test_loader:\n",
    "                images = Variable(images)                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iteration {}, loss {}, accuracy {}'.format(iter, loss.data[0], accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
